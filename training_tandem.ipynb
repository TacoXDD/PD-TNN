{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0edcec-3a07-42a5-98b8-259eabf14f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b9f1e9-c2e8-4a23-b41a-3c3bff65e421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_delta_E(Lab1, Lab2):\n",
    "    return np.sqrt(np.sum((Lab2 - Lab1) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb189b8-8716-41b5-a1af-1aa4c3cad8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabDataset(Dataset):\n",
    "    def __init__(self, npy_file):\n",
    "        self.data = np.load(npy_file, allow_pickle=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        mp = self.data[idx, :3]  \n",
    "        info1 = self.data[idx, 3:4]\n",
    "        info2 = self.data[idx, 4:5]\n",
    "        sp_half = self.data[idx, 6:49]\n",
    "        \n",
    "        inverse_input_sp = np.concatenate([self.data[idx, 6:49], self.data[idx, 49:]], axis=0)\n",
    "        forword_input_mp = np.concatenate([mp, info1, info2], axis=0)\n",
    "        forword_target_color = self.data[idx, 49:]\n",
    "\n",
    "        return torch.tensor(inverse_input_sp, dtype=torch.float32), \\\n",
    "               torch.tensor(forword_input_mp, dtype=torch.float32), \\\n",
    "               torch.tensor(forword_target_color, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913bd386-6bc5-4faf-907f-a03e038330fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "set_seed(0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f013bbdf-4e8f-4b54-b3ad-15fee0f748f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InverseDesignNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(3, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 5),\n",
    "        )\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "class ForwardModelingNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(5, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 3)\n",
    "        )\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "class TandemNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.inverse_design = InverseDesignNetwork()\n",
    "        self.forward_modeling = ForwardModelingNetwork()\n",
    "\n",
    "    def forward(self, x):\n",
    "        inverse_output_mp = self.inverse_design(x)\n",
    "        forward_output_color = self.forward_modeling(inverse_output_mp)\n",
    "        \n",
    "        return inverse_output_mp, forward_output_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09babe9b-8927-4d3a-b028-9165222b1724",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta_e_loss(pred, target):\n",
    "    return torch.sqrt(torch.sum((pred - target) ** 2, dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a9e0cf-3c53-4cc6-823b-cb52eed87605",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_results = []\n",
    "\n",
    "for run_time in tqdm(range(5)):\n",
    "    set_seed(run_time)  \n",
    "\n",
    "    epochs = 4000\n",
    "\n",
    "    train_dataset = LabDataset(f'dataset/npy/raw_random_train_sp_color.npy') #1013_random_train_sp_color\n",
    "    val_dataset = LabDataset(f'dataset/npy/raw_random_val_sp_color.npy')\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "    model = TandemNetwork()\n",
    "\n",
    "    # Load pre-trained weights for the forward modeling network\n",
    "    model.forward_modeling.load_state_dict(torch.load('best_forward_color_.pth')) # best_forward_color_delta_e_3.499 #best_forward_color_delta_mp12\n",
    "    model = model.cuda()\n",
    "    \n",
    "    # Freeze the forward modeling network\n",
    "    for param in model.forward_modeling.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    loss_fn = nn.MSELoss().cuda()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=5e-3, weight_decay=1e-3)\n",
    "    lr_schedule = optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs*0.7, eta_min=5e-4)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in tqdm(range(epochs)): \n",
    "        model.train()  \n",
    "        for inverse_input_sp, forword_input_mp, forword_target_color in train_dataloader:\n",
    "            inverse_input_sp = inverse_input_sp.cuda()\n",
    "            forword_input_mp = forword_input_mp.cuda()\n",
    "            forword_target_color = forword_target_color.cuda()\n",
    "            \n",
    "            # Forward pass\n",
    "            inverse_output_mp, forward_output_color = model(forword_target_color)         \n",
    "            # loss = loss_fn(forward_output_color, forword_target_color) \n",
    "            loss = delta_e_loss(forward_output_color, forword_target_color).mean()\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        with torch.no_grad(): \n",
    "            val_losses = []\n",
    "            for inverse_input_sp, forword_input_mp, forword_target_color in val_dataloader:\n",
    "                inverse_input_sp = inverse_input_sp.cuda()\n",
    "                forword_input_mp = forword_input_mp.cuda()\n",
    "                forword_target_color = forword_target_color.cuda()\n",
    "            \n",
    "                # Forward pass\n",
    "                inverse_output_mp, forward_output_color = model(forword_target_color)         \n",
    "                # loss = loss_fn(forward_output_color, forword_target_color) \n",
    "                loss = delta_e_loss(forward_output_color, forword_target_color).mean()\n",
    "                \n",
    "                val_losses.append(loss.item())\n",
    "\n",
    "        avg_val_loss = sum(val_losses) / len(val_losses)\n",
    "        lr_schedule.step()\n",
    "\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), f'best_tandem_{run_time}.pth')  # save model weights\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(f'Epoch {epoch}, Training Loss: {loss.item()}, Validation Loss: {avg_val_loss}, Best Loss: {best_val_loss}')\n",
    "\n",
    "    print(f'Best Loss: {best_val_loss}')\n",
    "\n",
    "    test_data = np.load(f'dataset/npy/raw_random_test_sp_color.npy')\n",
    "\n",
    "    mp = test_data[:, :3]  \n",
    "    info1 = test_data[:, 3:4]\n",
    "    info2 = test_data[:, 4:5]\n",
    "\n",
    "    inverse_input_sp = torch.tensor(test_data[:, 6:][:, ::2], dtype=torch.float32)\n",
    "    inverse_input_sp = torch.tensor(np.concatenate([test_data[:, 6:49], test_data[:, 49:]], axis=1), dtype=torch.float32)\n",
    "\n",
    "    forword_input_mp = torch.tensor(np.concatenate([mp, info1, info2], axis=1), dtype=torch.float32)\n",
    "    forword_target_color = torch.tensor(test_data[:, 49:], dtype=torch.float32)\n",
    "\n",
    "    test_dataset = TensorDataset(inverse_input_sp, forword_input_mp, forword_target_color)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=1)\n",
    "\n",
    "    model = TandemNetwork()\n",
    "    model.load_state_dict(torch.load(f'best_tandem_{run_time}.pth'))\n",
    "    model.forward_modeling.load_state_dict(torch.load('best_forward_color.pth'))\n",
    "    model.eval()\n",
    "    \n",
    "\n",
    "    all_delta_e = 0\n",
    "    all_mae = 0\n",
    "\n",
    "    for inverse_input_sp, forword_input_mp, forword_target_color in test_dataloader:\n",
    "        with torch.no_grad():\n",
    "            inverse_output_mp, forward_output_color = model(forword_target_color) \n",
    "\n",
    "            predicted_color = forward_output_color[0].numpy()\n",
    "            target_color = forword_target_color[0].numpy()\n",
    "\n",
    "            delta_e = calculate_delta_E(predicted_color, target_color)\n",
    "\n",
    "            all_delta_e += delta_e\n",
    "\n",
    "    print(f'Test Delta E {run_time}: {np.round(all_delta_e / len(test_dataloader), 2)}')\n",
    "    \n",
    "    all_results.append(np.round(all_delta_e / len(test_dataloader), 2))\n",
    "    print('-----------------------------------------------')\n",
    "    \n",
    "print(f'All: {all_results}')\n",
    "print(f'Average: {np.round(np.mean(all_results), 2)}')\n",
    "print(f'STD: {np.round(np.std(all_results), 2)}')\n",
    "print(f'Min: {np.min(all_results)}')\n",
    "print(f'Max: {np.max(all_results)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
